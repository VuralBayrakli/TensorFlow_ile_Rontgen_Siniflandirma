{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff32005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a5a047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "data_dir = 'data/'  # Veri klasörünün yolu\n",
    "batch_size = 128  # Mini-batch boyutu\n",
    "\n",
    "# Veri dönüşümleri ve etiketleme işlemi\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9fc148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22db5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch, label_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4f5fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = []\n",
    "for i, l in zip(train_batch, label_batch):\n",
    "    new_dataset.append((i,l))\n",
    "    \n",
    "new_dataloader = DataLoader(new_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7358f3a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (regression_head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=4, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        \n",
    "        # Define the feature extraction backbone (equivalent to VGG16)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        # Define the classification head\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1),  # Change the output dimension to 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Define the regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone feature extraction\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Classification head\n",
    "        class_output = self.classification_head(features)\n",
    "        \n",
    "        # Regression head\n",
    "       \n",
    "        \n",
    "        return class_output\n",
    "\n",
    "# Create an instance of the model\n",
    "model = CustomModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39bf32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce31a824",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (regression_head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=4, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c58c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss --  tensor(0.6616, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pred --  tensor([1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<SqueezeBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "true label --  tensor([1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "acc --  62.5\n"
     ]
    }
   ],
   "source": [
    "img, label = next(iter(new_dataloader))\n",
    "\n",
    "\n",
    "logit = model(img)\n",
    "label = label.to(torch.float)\n",
    "loss = loss_fn(logit.squeeze(),label)\n",
    "pred = torch.round(torch.sigmoid(logit))\n",
    "acc = accuracy_fn(label, pred.squeeze())\n",
    "print(\"loss -- \",loss)\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"pred -- \", pred.squeeze())\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"true label -- \", label)\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"acc -- \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7aa0ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y = y.to(torch.float)\n",
    "        # 1. Forward pass\n",
    "        y_pred_logits = model(X)\n",
    "        y_pred = torch.round(torch.sigmoid(y_pred_logits)).squeeze().to(device)\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred_logits.squeeze(), y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y = y.to(torch.float)\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "            test_pred = torch.round(torch.sigmoid(test_pred_logits)).squeeze().to(device)\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred_logits.squeeze(), y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "603bf3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 1/3 [00:33<01:06, 33.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.73727 | Train accuracy: 46.88%\n",
      "Epoch: 1\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:57<00:28, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.73621 | Train accuracy: 46.88%\n",
      "Epoch: 2\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:23<00:00, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.73510 | Train accuracy: 46.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "from tqdm import tqdm\n",
    "# Measure time\n",
    "\n",
    "# Train and test model \n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=new_dataloader, \n",
    "        model=model, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85185b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss --  tensor(0.6615, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pred --  tensor([1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<SqueezeBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "true label --  tensor([1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "acc --  62.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img.to(device)\n",
    "label.to(device)\n",
    "\n",
    "logit = model(img).to(device)\n",
    "label = label.to(torch.float).to(device)\n",
    "loss = loss_fn(logit.squeeze().to(device),label)\n",
    "pred = torch.round(torch.sigmoid(logit))\n",
    "acc = accuracy_fn(label, pred.squeeze())\n",
    "print(\"loss -- \",loss)\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"pred -- \", pred.squeeze())\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"true label -- \", label)\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"acc -- \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "35d934e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomResnet18(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        resnet18 = timm.create_model('resnet18', pretrained=True)\n",
    "        # here we get all the modules(layers) before the fc layer at the end\n",
    "        # note that currently at pytorch 1.0 the named_children() is not supported\n",
    "        # and using that instead of children() will fail with an error\n",
    "        self.features = nn.ModuleList(resnet18.children())[:-2]\n",
    "        # Now we have our layers up to the fc layer, but we are not finished yet \n",
    "        # we need to feed these to nn.Sequential() as well, this is needed because,\n",
    "        # nn.ModuleList doesnt implement forward() \n",
    "        # so you cant do sth like self.features(images). Therefore we use \n",
    "        # nn.Sequential and since sequential doesnt accept lists, we \n",
    "        # unpack all the items and send them like this\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        print(self.features)\n",
    "        # now lets add our new layers \n",
    "        in_features = resnet18.fc.in_features\n",
    "        # from now, you can add any kind of layers in any quantity!  \n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1),  # Change the output dimension to 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Define the regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # initialize all fc layers to xavier\n",
    "       \n",
    "    def forward(self, input_imgs):\n",
    "       # now in forward pass, you have the full control, \n",
    "       # we can use the feature part from our pretrained model  like this\n",
    "        x = self.features(input_imgs)\n",
    "        # since we are using fc layers from now on, we need to flatten the output.\n",
    "        # we used the avgpooling but we still need to flatten from the shape (batch, 1,1, features)\n",
    "        # to (batch, features) so we reshape like this. input_imgs.size(0) gives the batchsize, and \n",
    "        # we use -1 for inferring the rest\n",
    "        # Classification head\n",
    "        class_output = self.classification_head(x)\n",
    "        \n",
    "        # Regression head\n",
    "        regress_output = self.regression_head(x)\n",
    "        \n",
    "        return class_output, regress_output\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39e043f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "class customResnet50(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        resnet50 = timm.create_model('resnet50', pretrained=True)\n",
    "        self.features = nn.ModuleList(resnet50.children())[:-2]\n",
    "        # Now we have our layers up to the fc layer, but we are not finished yet \n",
    "        # we need to feed these to nn.Sequential() as well, this is needed because,\n",
    "        # nn.ModuleList doesnt implement forward() \n",
    "        # so you cant do sth like self.features(images). Therefore we use \n",
    "        # nn.Sequential and since sequential doesnt accept lists, we \n",
    "        # unpack all the items and send them like this\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        # now lets add our new layers \n",
    "        in_features = resnet50.fc.in_features\n",
    "        new_cnn_layer = nn.Conv2d(in_channels=in_features, out_channels=2048, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 1),  # Change the output dimension to 1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        class_output = self.classification_head(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return class_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7f6de11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5083]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.2460, 0.2545, 0.2391, 0.2605]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyCustomResnet18()\n",
    "model(img.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "62bde563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (regression_head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=4, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        \n",
    "        # Define the feature extraction backbone (equivalent to VGG16)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Define the classification head\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1),  # Change the output dimension to 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Define the regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone feature extraction\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Classification head\n",
    "        class_output = self.classification_head(features)\n",
    "        \n",
    "        # Regression head\n",
    "        regress_output = self.regression_head(features)\n",
    "        \n",
    "        return class_output, regress_output\n",
    "\n",
    "# Create an instance of the model\n",
    "model = CustomModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cd508752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5017]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.2433, 0.2534, 0.2483, 0.2549]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1ad00e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "model = timm.create_model(\"resnet50\", pretrained=True)\n",
    "in_features = model.fc.in_features\n",
    "# Örnek bir girdi boyutunu alalım\n",
    "model = torch.nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "\n",
    "classification_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 1),  # Change the output dimension to 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Define the regression head\n",
    "regression_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "print(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "144de840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "class customResnet50(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        resnet50 = timm.create_model('resnet50', pretrained=True)\n",
    "        self.features = nn.ModuleList(resnet50.children())[:-2]\n",
    "        # Now we have our layers up to the fc layer, but we are not finished yet \n",
    "        # we need to feed these to nn.Sequential() as well, this is needed because,\n",
    "        # nn.ModuleList doesnt implement forward() \n",
    "        # so you cant do sth like self.features(images). Therefore we use \n",
    "        # nn.Sequential and since sequential doesnt accept lists, we \n",
    "        # unpack all the items and send them like this\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        # now lets add our new layers \n",
    "        in_features = resnet50.fc.in_features\n",
    "        new_cnn_layer = nn.Conv2d(in_channels=in_features, out_channels=2048, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            self.features,\n",
    "            new_cnn_layer,\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        \n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 1),  # Change the output dimension to 1\n",
    "        )\n",
    "        \n",
    "        # Define the regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 4),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        class_output = self.classification_head(x)\n",
    "        \n",
    "        regression_output = self.regression_head(x)\n",
    "        \n",
    "        return class_output, regression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ed5d2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = customResnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf0d6784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0153]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.0305, -0.0180,  0.0380, -0.0464]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.unsqueeze(dim=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
